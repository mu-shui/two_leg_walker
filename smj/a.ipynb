import gymnasium as gym
import numpy as np


class CustomWalker2dEnv(gym.Wrapper):
    """
    自定义Walker2d环境：继承Gym原生Walker2d-v4，添加2个核心功能：
    1. 明确状态空间（关节角度、角速度、末端执行器位置）
    2. 添加地面摩擦随机扰动（增强鲁棒性）
    （奖励函数使用MuJoCo原生逻辑，不做自定义修改）
    """
    def __init__(self, render_mode="human"):
        # 1. 加载Gym原生Walker2d-v4环境（基础仿真平台）
        # 原生环境已包含二足物理模型：头部+大腿+小腿+双足+旋转关节（6个铰链连接）
        super().__init__(
            gym.make(
                "Walker2d-v4",  # 实验要求的环境版本
                render_mode=render_mode,  # "human"显示仿真窗口，"rgb_array"仅输出图像数据
                ctrl_cost_weight=0.1,  # 原生控制成本权重（保留原生设置）
                healthy_z_range=(0.8, 2.0),  # 原生健康状态判定（保留）
                reset_noise_scale=5e-3  # 初始状态随机扰动（保留）
            )
        )
        
        # 2. 明确状态空间结构（实验要求：关节角度、角速度、末端执行器位置）
        # 原生Walker2d-v4的观测维度为17，此处拆解各维度含义（便于后续调试）
        self.observation_dim_info = {
            "关节角度（6个）": slice(0, 6),    # 髋部（2个）、膝部（2个）、踝部（2个）关节角度
            "关节角速度（6个）": slice(6, 12), # 对应6个关节的角速度
            "末端执行器位置（4个）": slice(12, 16), # 双足末端的x/y坐标（每足2个维度）
            "躯干z轴速度（1个）": slice(16, 17) # 补充：躯干垂直速度（辅助判断稳定性）
        }
        
        # 3. 动作空间：原生已为连续值（6个关节的扭矩，范围[-1,1]），无需额外定义
        # 打印动作空间信息（验证是否符合实验要求）
        print(f"动作空间：连续关节扭矩，维度={self.action_space.shape[0]}，范围=[{self.action_space.low[0]}, {self.action_space.high[0]}]")
        
        # 4. 扰动参数：地面摩擦系数随机范围（实验要求的“地面摩擦变化”）
        self.min_friction = 0.3  # 最小摩擦系数（模拟光滑地面）
        self.max_friction = 1.0  # 最大摩擦系数（模拟粗糙地面）
        self.perturb_prob = 0.1  # 每步触发摩擦扰动的概率（10%，平衡扰动与稳定性）

    def step(self, action):
        """
        每步交互逻辑：执行动作→更新环境→添加扰动→保留原生奖励
        返回：观测（状态）、原生奖励、终止标志、截断标志、额外信息
        """
        # 1. 执行动作（直接使用原生环境step，保留原生奖励）
        obs, native_reward, terminated, truncated, info = super().step(action)
        
        # 2. 添加地面摩擦随机扰动（实验要求：增强鲁棒性）
        if np.random.random() < self.perturb_prob:
            # 随机生成新摩擦系数（在min和max之间）
            new_friction = np.random.uniform(self.min_friction, self.max_friction)
            # 修改MuJoCo物理模型的地面摩擦系数（geom[0]对应地面几何体）
            self.env.unwrapped.model.geom_friction[0] = new_friction
            # 记录扰动信息（便于调试）
            info["ground_friction"] = round(new_friction, 2)
        
        # 3. 补充状态信息到info（便于后续分析：关节角度、角速度、末端位置）
        info["joint_angles"] = obs[self.observation_dim_info["关节角度（6个）"]]
        info["joint_velocities"] = obs[self.observation_dim_info["关节角速度（6个）"]]
        info["end_effector_pos"] = obs[self.observation_dim_info["末端执行器位置（4个）"]]
        # 补充原生x轴速度（从原生环境数据中提取，保持与原生奖励逻辑一致）
        info["x_velocity"] = self.env.unwrapped.data.qvel[0]
        
        # 返回结果：保留原生奖励，其他信息不变
        return obs, native_reward, terminated, truncated, info

    def reset(self, **kwargs):
        """重置环境：恢复初始状态+重置地面摩擦系数"""
        obs, info = super().reset(** kwargs)
        # 重置地面摩擦为默认值（避免扰动累积）
        self.env.unwrapped.model.geom_friction[0] = 0.7  # 默认摩擦系数（中等粗糙地面）
        info["ground_friction"] = 0.7  # 记录初始摩擦
        return obs, info


# ------------------- 测试代码：验证环境是否符合要求 -------------------
if __name__ == "__main__":
    # 1. 初始化自定义环境
    env = CustomWalker2dEnv(render_mode="human")  # "human"显示仿真窗口
    
    # 2. 重置环境（获取初始状态）
    obs, info = env.reset()
    print("\n初始状态信息：")
    # 从obs中提取初始状态（reset后还没执行step，info中没有joint相关键）
    joint_angles = obs[env.observation_dim_info["关节角度（6个）"]]
    joint_velocities = obs[env.observation_dim_info["关节角速度（6个）"]]
    end_effector_pos = obs[env.observation_dim_info["末端执行器位置（4个）"]]
    print(f"- 关节角度（6个）：{np.round(joint_angles, 3)}")
    print(f"- 关节角速度（6个）：{np.round(joint_velocities, 3)}")
    print(f"- 末端执行器位置（4个）：{np.round(end_effector_pos, 3)}")
    print(f"- 初始地面摩擦：{info['ground_friction']}")
    
    # 3. 运行1000步仿真（测试扰动、原生奖励、状态更新）
    total_steps = 1000
    total_reward = 0.0
    for step in range(total_steps):
        # 随机采样动作（后续可替换为强化学习策略输出）
        action = env.action_space.sample()
        
        # 执行一步交互（step后info中会有joint相关键和x_velocity）
        obs, reward, terminated, truncated, info = env.step(action)
        
        # 累积总奖励+打印关键信息（每100步打印一次，避免输出过多）
        total_reward += reward
        if (step + 1) % 100 == 0:
            print(f"\n第{step+1}步信息：")
            print(f"- 累计奖励（原生）：{round(total_reward, 2)}")
            print(f"- 当前行走速度：{round(info['x_velocity'], 3)} m/s")
            print(f"- 当前地面摩擦：{info.get('ground_friction', 0.7)}")  # 显示扰动后的摩擦
            print(f"- 关节角度（前3个）：{np.round(info['joint_angles'][:3], 3)}")  # 打印部分关节角度
        
        # 若跌倒或超时，重置环境
        if terminated or truncated:
            print(f"\n第{step+1}步：{'跌倒' if terminated else '超时'}，重置环境")
            obs, info = env.reset()
            total_reward = 0.0  # 重置累积奖励
    
    # 4. 关闭环境（释放资源）
    env.close()
    print("\n环境测试完成！")
